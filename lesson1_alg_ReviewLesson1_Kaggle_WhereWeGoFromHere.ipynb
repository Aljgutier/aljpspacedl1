{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digression ...student blogging ...  beginning of Lesson 3\n",
    "\n",
    "Several people have been blogging or posting content for other to use  \n",
    "\n",
    "#### Rashima  \n",
    "    https://github.com/reshamas/fastai_deeplearn_part1  \n",
    "\n",
    "#### Pavel Surmenok ... learning rate optimization notes  \n",
    "    Deep dive, summary of notes, for learning rate optimization   \n",
    "    https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0  \n",
    "\n",
    "#### Radek ... A practioners guide to PyTorch\n",
    "    A little more advanced. Numerical programming in general.  \n",
    "    \"https://towardsdatascience.com/a-practitioners-guide-to-pytorch-1d0f6a238040\n",
    "\n",
    "#### Miguel ... Visualizing the relationship between Learning and Batch Size\n",
    "    tried different batch sizes and learning rates  \n",
    "    https://miguel-data-sc.github.io/2017-11-05-first/  \n",
    "\n",
    "\n",
    "#### Samyam Bhutani  ... Convolutional Neural Network in 5 minutes\n",
    "    https://hackernoon.com/convolutional-neural-network-in-5-minutes-8f867eb9ca39 \n",
    "\n",
    "\n",
    "#### Anand Saha ... Decoding the ResNet architecture\n",
    "    http://teleported.in/posts/decoding-resnet-architecture/\n",
    "\n",
    "#### Apil Tamang ... Yet another ResNet Tutorial\n",
    "    https://medium.com/@apiltamang/yet-another-resnet-tutorial-or-not-f6dd9515fcd7\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course Structure\n",
    "\n",
    "So far we did an intro to CNN's without theory or how they work. We have seen how to build a model that works exceptionally well. We will review some of that today. We will also begin to dig into some uderlying theory.\n",
    "\n",
    "We will also intro application area: logistics, forecasting, financial data, language RNN, Collaborative filtering recommendations. Similar to what we did for images. Here's how you get state of the art result without theory. Then go back in reverse order dig into the theory and math and code underneath, first with collaborative filtering, structured data, cnn (images), an finally deep dive into recurrent neural networks.\n",
    "\n",
    "\n",
    "<img src=\"./Lesson3-WhereWeGoFromHere.png\" style='width:500px;height:500px;'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some review from last time - dog breads\n",
    "\n",
    "\n",
    "#### Download data from kaggle and/or anywhere else\n",
    " ##### Kaggle ... use Kaggle CLI. \n",
    "  - github ... floydwch/kaggle-cli\n",
    "  - already in environment ... vim environment.yml\n",
    "  - download from Kaggle website, if website changes it breaks so get recent version. \n",
    "  - pip install kaggle-cli --upgrade\n",
    "  - Reshma Kaggle CLI Wiki \n",
    "  - kg download - username -p password -c competition_name  ... at Kaggle URL, after .../c /competition-name\n",
    "  - make sure that ... download at least once to accept the rules ...need to signin with user password, not Google, may need to click forget password on kaggle ... ... \n",
    "  - will get folder with all competition data ... \n",
    "##### Maybe you don't want all the data.... for exampel  Planet data (kaggle) has Tiff (19 GB) and JPG (600 MB)\n",
    "  - Here's a cool tip\n",
    "  - chrome extension CurlWget\n",
    "  - now when you try and download something start downloading in Chrome ... cancel it ... now go to yellow button (getCurl ... has cookies, login info itself) top right chrome ... copy and paste the command into paperspace terminal ... has all cookies and headers to dowload the file ... all stuff that is hidden behind a login ... VERY USEFUL for data science\n",
    "  \n",
    "##### where to put data\n",
    "  - data is usually in a sub directory of notebook\n",
    "  - courses dl1 folder, data is a symbolic link to a different drive\n",
    "  - sim links are like aliases \n",
    "  - use ls -l flag\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review the step by step process\n",
    "start by turning data augmentation on ...  aug transforms = side on or top down ... \n",
    "\n",
    "For example, when we trained dogs and cats. The layers are important but the weights we need to adjust. The later ones need more trained. When we start with pre-trained. Last fully connecxted randomly set and this is what we initially trained. If like imagenet then this is all we need. When we unfreeze, we set learning rates for early layers set learning rate low because don't want to change much. For satellite this is no longer true and still need to adjust more relative to the dogs and cats situation. Online they talk about unfreezing subsets of layers. This approach of differential learning rates seems more effective than unfreezing subsets. You could skip this training just the last layer and go to differential but prob dont want to. The CNN layers are pretrainined, and at least better than nothing. However fully connected weights are fully random and need to do some training befgore unfreezing.\n",
    "\n",
    "SGD will change weights on the kernals. The architecture will not change. \n",
    "\n",
    "Activations are calculated from the weights and labels (inputs), layer inputs. \n",
    "\n",
    "On satellite started with 64 x 64 ... How we get that 64 x 64 depends on transforms. By default, takes the smallest edge and zooms out and then takes the center crop. Data augmentation takes randomly chosen crop.\n",
    "\n",
    "Test time augmentation also important.\n",
    "\n",
    "We will learn about loss function next week. The metric is the thing that is printed. Interesting question could possibly train on single class data and apply to multiclass.\n",
    "\n",
    "How do differential learning rates spread accross. There is concept of layer groups. In Fastai decides for you how to split. Last one fully connected. The others split approximately in halves. There are ways to overide. There are ways to dump the layers of the model. (learn.summary, spits out everything ... will get layer names and sizes, number of channels).  4 dimensional mini-batch .. number of images in minibatch dynamce, 3 channels 64 x 64 images \n",
    "\n",
    "Learning rate finder, if have tiny data set, need to make mini batches small. \n",
    "\n",
    "1. Set precompute=True\n",
    "1. Find Learning rate ...  Use `lr_find()` to find highest learning rate where loss is still clearly improving\n",
    "1. Train last layer from precomputed activations for 1-2 epochs ... pre-trainined image net normal pictures \n",
    "1. Turn off precompute ... Train last layer with data augmentation (i.e. precompute=False) for 2-3 epochs with cycle_len=1\n",
    "1. Unfreeze all layers\n",
    "1. Set earlier layers to 3x-10x lower learning rate than next higher layer ... in this case 10x k ... when starting things with resnet then 10x if not at all like resnet images eg satallite images not like resnet then 3x will train longer for these type of images \n",
    "1. Use `lr_find()` again ... we didn't do this but we could to see if still looks the same from learning rate pserspective ... will print the learning rate of the last layer\n",
    "1. Train full network with cycle_mult=2 until over-fitting\n",
    "\n",
    "\n",
    "=>Lets do this again for another data set ... look at the lesson1-breeds.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entire process ( In a few frames) - Minimum Steps is shown below\n",
    "  (skipped downloading data from kaggle)\n",
    "``` \n",
    "   # import libraries \n",
    "   from fastai. conv_learner import *  # this library imports everything else\n",
    "   PATH = \"data/dogscats               # path where the data is ... \n",
    "   sz = 224; bs=64                     # image size nd batch size (images per batch)\n",
    "                                       # sz = image size, initially may change this to smaller to run faster\n",
    "\n",
    "   tfms = tfms_from_model(resnet50, sz, aug_tfms=transforms_side_on, max_zoom=1.1)  \n",
    "                                               # transform data, side_on \n",
    "                                               # photos, zoom by 10%  \n",
    "                                               # data is in paths dogs, a                                                                                      # paths cats ... you can rename this \n",
    "   data = ImageClassifierData.from_paths(PAT, tfms=tfms, bs=bs)  \n",
    "                                               # from paths ... data, dog train,vaiid,test\n",
    "                                               # fll in test name if going to submit to \n",
    "                                               # Kaggle\n",
    "                                               \n",
    "   learn = ConvLearner.pretrained(resnet50, data) # creae model from pre-trained ResNet50 model, with our data\n",
    "   %time learn.fit(1e-2, 3, cycle_len=1)          \n",
    "                                                   # call fit, 3 cycles of length 1\n",
    "                                                   # by default, all but last few layers frozen, \n",
    "                                                   # takes 2.5 minutes\n",
    "                                                   # could say precompute = True, a shortcut => faster\n",
    "                                                   # data augmentation doesnt work if precompute=True\n",
    "                                                   # learning rate 1 e-2\n",
    "                                                   # 3 cycles of n cycles (cycle_len)\n",
    "                                                   #   The number of epochs between resetting learning \n",
    "                                                   #   rate is set by cycle_len, and the number of times \n",
    "                                                   #   this happens is refered to as the number of cycles\n",
    "                                                   # cycle_len =1 ... \"cool trick\" stochastic gradient \n",
    "                                                   #   descents with restart\n",
    "                                                   #   cycle_len = 1, change learning rate after n cycles\n",
    "                                                   #   as you get to the right spot. Start to decrease\n",
    "                                                   #   learning rate\n",
    "                                                   #   slow steps until get to the right spot. \n",
    "                                                   #   With more iterations\n",
    "                                                   #  because activations are frozen\n",
    "   learn.unfreeze() \n",
    "   learn.bn_freeze(True)                          \n",
    "                                                   # bn_freeze larger data set similar imagenet side_on\n",
    "                                                   #  similar objexts, 200 to 500 pixels ... then \n",
    "                                                   #  add this line.. batch norm moving avg's not updated\n",
    "                                                   #  not supported by any other library\n",
    "                                                   \n",
    "   %time learn.fit([1e-5, 1e-4, 1e-2], 1, cycle_len=1)            # train again\n",
    "   %time log_preds, y = learn.TTA()                               # test time augmentation to get best \n",
    "   metrics.log_loss(y, np.exp(log_preds)), accuracy(log_preds,y)  # see how well it did\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Tricks that will be useful\n",
    "\n",
    "- if not quite sure what method ... hit tab to get a list of methods\n",
    "- shift tab to see arguements,  parameters to a method\n",
    "- shift tab tab ... brings up the documentation\n",
    "- shift tab tab tab ... separate window with all the information\n",
    "- ?function ... will bring up documetation\n",
    "- ??learn.predict ... pop up the source code\n",
    "- Fastai method usually less 1/2 screen of code\n",
    "- button on browser .. will bring up keybard shortcuts palette ... try and learn a few a day\n",
    "- SHUTDOWN YOUR PAPERSPACE MACHINE ... same with Crestle ... \n",
    "- Go to forums and look at course.fast.ai for course information to get updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other libraries ... (Keras)\n",
    "- Keras ... mainly sits on top of tensorFLow\n",
    "- Keras lesson 1, parts of lesson 1 in Keras\n",
    "- Keras also assumes ... validation set file, training set file \n",
    "- keras has many more things to set, if not correct all breakds\n",
    "- rather than single data object ... have to create a data generater, with data augmentation, and normalization\n",
    "- copy and past keras from internet is a good way to get started, not a set of \n",
    "- below cut and paste from keras documentation \n",
    "\n",
    "- SEE THE FILE keras_lesson1.ipynb and keras_lesson1_alg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review learning rate optimization here\n",
    "\n",
    "#### Pavel Surmenok ... learning rate optimization notes  \n",
    "    Deep dive, summary of notes, for learning rate optimization   \n",
    "    https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review also\n",
    "\n",
    ">  Lesson1_alg  Cats and Dogs  \n",
    ">  lesson1_breeds_alg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to Kaggle (see lesson1-breed for more notes)\n",
    "\n",
    "- Go to Kaggle website\n",
    "  - for every competition there is a section called evalutaion and it will tell you what to submit\n",
    "  - copied and pased a couple of lin\n",
    "\n",
    "... copied first two lines, file format, below,  \n",
    "... first line starts with \"id\" and csv list of dogbreeds  \n",
    "... then, each line has the i-th id's followed by probability of dog breeds\n",
    "\n",
    "```\n",
    "   id,affenpinscher,afghan_hound,...,yorkshire_terrier\n",
    "   000261fb3cbb32d8935728e486796680,0.0083,0,...,0.0083\n",
    "\n",
    "```\n",
    "\n",
    "So, how do we create that.   \n",
    "\n",
    "Inside data object there is .classes (data.classes), alphabetical order of classes  \n",
    "\n",
    "Inside **data.test_ds.fname** data set, there are all the filenames  \n",
    "\n",
    "Dog breeds not provided in Keras style format, but instead CSV file of labels   \n",
    "  ... use ImageClassiferData.from_csv (fastai) rather than ImageClassifierData.from_paths\n",
    "\n",
    "from CSV file has classes (labels) data.classes\n",
    "\n",
    "from data.test_ds.fnames we have the test images and filenames \n",
    "\n",
    "Good idea to use TTA\n",
    "\n",
    "```\n",
    "   log_preds, y = learn.TTA(is_test=True) # use test dataset rather than validation dataset\n",
    "                                          # is_test = True ... predictions on test set rather than validation\n",
    "                                          # by definition dont know labels for the test set\n",
    "                                          # by default kaggle uses log so use exp to convert back to linear\n",
    "\n",
    "   probs = np.mean(np.exp(log_preds),0)\n",
    "   #accuracy_np(probs, y), metrcs.log_loss(y, probs) # This does not make sense since test dataset has no labels\n",
    "   \n",
    "   \n",
    "   probs.shape # (n_images, n_classes)\n",
    "     =>  (10357, 120)\n",
    "     \n",
    "   test set 10K images with 120 possible breeds ... need to convert it\n",
    "   easiest way to do it is with pandas\n",
    "     \n",
    "   df = pd.DataFrame(probs)     # pass in matrix\n",
    "   df.columns = data.classes    # name columns\n",
    "   \n",
    "   df.insert(0, 'id', [o[5:-4] for o in data.test_ds.fnames])   # insert col in position 0 that contains fnames\n",
    "   \n",
    "   notice filenames five letters 'test/123958672... .jpg' start we dont want and at end don't want\n",
    "   so, subset\n",
    "   now df should be correct\n",
    "   \n",
    "   next call df.to_csv ... save to file ... compress it, can be big ... ziped csv file on the servier\n",
    "      wherever you are running \n",
    "      \n",
    "   SUBM = f'{PATH}/subm/'\n",
    "   os.makedirs(SUBM, exist_ok=True)\n",
    "   df.to_csv(f'{SUBM}subm.gz', compression='gzip', index=False)\n",
    "   \n",
    "   \n",
    "   get it back to your computer, so you can double check and play\n",
    "   or, use Kaggle CLI\n",
    "   use FileLink\n",
    "   \n",
    "   FileLink(f'P{afds}subm.gz'}   ... with path on servier will give back URL and iwll download file on server\n",
    "                                 URL cick on download file from server on your computer \n",
    "                                 will be saverd to downloads .... check it out and submit to Kaggle\n",
    "                                 \n",
    "   \n",
    "   ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
