{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rossman Time-Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook only contains the forecasting part  \n",
    "The feature engineering is in a separate notebook and saved to the following files\n",
    "   -  \"PATH/joined\"\n",
    "   -  \"PATH/joined_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.structured import *\n",
    "from fastai.column_data import *\n",
    "np.set_printoptions(threshold=50, edgeitems=20)\n",
    "PATH='data/rossmann/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.read_feather(f'{PATH}/joined')\n",
    "joined_test = pd.read_feather(f'{PATH}joined_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open',\n",
       "       'Promo', 'StateHoliday', 'SchoolHoliday', 'Year', 'Month', 'Week',\n",
       "       'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n",
       "       'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start',\n",
       "       'Elapsed', 'StoreType', 'Assortment', 'CompetitionDistance',\n",
       "       'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\n",
       "       'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval', 'State', 'file',\n",
       "       'week', 'trend', 'file_DE', 'week_DE', 'trend_DE', 'Date_DE',\n",
       "       'State_DE', 'Month_DE', 'Day_DE', 'Dayofweek_DE', 'Dayofyear_DE',\n",
       "       'Is_month_end_DE', 'Is_month_start_DE', 'Is_quarter_end_DE',\n",
       "       'Is_quarter_start_DE', 'Is_year_end_DE', 'Is_year_start_DE',\n",
       "       'Elapsed_DE', 'Max_TemperatureC', 'Mean_TemperatureC',\n",
       "       'Min_TemperatureC', 'Dew_PointC', 'MeanDew_PointC', 'Min_DewpointC',\n",
       "       'Max_Humidity', 'Mean_Humidity', 'Min_Humidity',\n",
       "       'Max_Sea_Level_PressurehPa', 'Mean_Sea_Level_PressurehPa',\n",
       "       'Min_Sea_Level_PressurehPa', 'Max_VisibilityKm', 'Mean_VisibilityKm',\n",
       "       'Min_VisibilitykM', 'Max_Wind_SpeedKm_h', 'Mean_Wind_SpeedKm_h',\n",
       "       'Max_Gust_SpeedKm_h', 'Precipitationmm', 'CloudCover', 'Events',\n",
       "       'WindDirDegrees', 'StateName', 'CompetitionOpenSince',\n",
       "       'CompetitionDaysOpen', 'CompetitionMonthsOpen', 'Promo2Since',\n",
       "       'Promo2Days', 'Promo2Weeks', 'AfterSchoolHoliday',\n",
       "       'BeforeSchoolHoliday', 'AfterStateHoliday', 'BeforeStateHoliday',\n",
       "       'AfterPromo', 'BeforePromo', 'SchoolHoliday_bw', 'StateHoliday_bw',\n",
       "       'Promo_bw', 'SchoolHoliday_fw', 'StateHoliday_fw', 'Promo_fw'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for DL\n",
    "\n",
    "from here on take it as given that all the above has been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844338"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen',\n",
    "    'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n",
    "    'State', 'Week', 'Events', 'Promo_fw', 'Promo_bw', 'StateHoliday_fw', 'StateHoliday_bw',\n",
    "    'SchoolHoliday_fw', 'SchoolHoliday_bw']\n",
    "\n",
    "contin_vars = ['CompetitionDistance', 'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC',\n",
    "   'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', \n",
    "   'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',\n",
    "   'AfterStateHoliday', 'BeforeStateHoliday', 'Promo', 'SchoolHoliday']\n",
    "\n",
    "n = len(joined); n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep = 'Sales'\n",
    "joined = joined[cat_vars+contin_vars+[dep, 'Date']].copy()\n",
    "joined_test[dep] = 0\n",
    "joined_test = joined_test[cat_vars+contin_vars+[dep, 'Date', 'Id']].copy()\n",
    "\n",
    "# change columns into categories\n",
    "# Loop through cat_vars and turn applicable data frame columns into categorical columns.\n",
    "for v in cat_vars: joined[v] = joined[v].astype('category').cat.as_ordered()\n",
    "apply_cats(joined_test, joined)\n",
    "\n",
    "# change continuous variables into 32-bit floating point\n",
    "# PyTorch expects 32-bt floating point\n",
    "# 1's and 0's will be 32-bt floating point\n",
    "for v in contin_vars:\n",
    "    joined[v] = joined[v].fillna(0).astype('float32')\n",
    "    joined_test[v] = joined_test[v].fillna(0).astype('float32')\n",
    "    \n",
    "#samp_size = n\n",
    "joined_samp = joined.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now process our data... Notice that pandas still displays categories as strings (e.g., StoreType). Even though we set some of the columns as “category” (e.g. ‘StoreType’, ‘Year’), Pandas still display as string in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y, nas, mapper = proc_df(joined_samp, 'Sales', do_scale=True)\n",
    "yl = np.log(y)\n",
    "\n",
    "joined_test = joined_test.set_index(\"Date\")\n",
    "\n",
    "df_test, _, nas, mapper = proc_df(joined_test, 'Sales', do_scale=True, skip_flds=['Id'],\n",
    "                                  mapper=mapper, na_dict=nas)\n",
    "\n",
    "val_idx = np.flatnonzero(\n",
    "    (df.index<=datetime.datetime(2014,9,17)) & (df.index>=datetime.datetime(2014,8,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you take the log of the data, getting the root mean squared error will actually get you the root mean square percentage error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_y(a): return np.exp(a)\n",
    "\n",
    "def exp_rmspe(y_pred, targ):\n",
    "    targ = inv_y(targ)\n",
    "    pct_var = (targ - inv_y(y_pred))/targ\n",
    "    return math.sqrt((pct_var**2).mean())\n",
    "\n",
    "max_log_y = np.max(yl)\n",
    "y_range = (0, max_log_y*1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 13s, sys: 1.6 s, total: 10min 15s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9822734429299947,\n",
       " 0.9312465831110313,\n",
       " 0.9248344812310892,\n",
       " 0.10887143382612567)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((val,trn), (y_val,y_trn)) = split_by_idx(val_idx, df.values, yl)\n",
    "mrf = RandomForestRegressor(n_estimators=40, max_features=0.99, min_samples_leaf=2,\n",
    "                          n_jobs=-1, oob_score=True)\n",
    "%time mrf.fit(trn, y_trn);\n",
    "\n",
    "preds = mrf.predict(val)\n",
    "mrf.score(trn, y_trn), mrf.score(val, y_val), mrf.oob_score_, exp_rmspe(preds, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_data_frame(PATH, val_idx, df, yl.astype(np.float32), cat_flds=cat_vars, bs=128,\n",
    "                                       test_df=df_test)\n",
    "# Some categorical variables have a lot more levels than others. \n",
    "#   Store, in particular, has over a thousand!\n",
    "cat_sz = [(c, len(joined_samp[c].cat.categories)+1) for c in cat_vars]\n",
    "\n",
    "# We use the *cardinality* of each variable (that is, its number of unique values) to decide how \n",
    "#  large to make its *embeddings*. Each level will be associated with a vector with length defined as below.\n",
    "emb_szs = [(c, min(50, (c+1)//2)) for _,c in cat_sz]\n",
    "\n",
    "# Inputs\n",
    "#  Pass in No. of continuous variables =  \n",
    "#       total Variables - Categoricals. \n",
    "#  NN knows how to create continuous and cat variables\n",
    "#  Categorical variable dropouts ... .04\n",
    "#  Output of last linear layer ... 1, predicting single number sales\n",
    "#  Activations in first and second linear layers ... [1000,500]\n",
    "#  Dropouts in first and second linear layers ... [.001,0.1]\n",
    "# need to know embeddings matrix size\n",
    "# in earlier models did not pass in the data ... in this case the model depends on the data\n",
    "# the data object creates the learner\n",
    "m = md.get_learner(emb_szs, len(df.columns)-len(cat_vars),\n",
    "                   0.04, 1, [1000,500], [0.001,0.01], y_range=y_range)\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c469dee7ca48409f517ad77662e007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                       \n",
      "    0      0.013347   0.021569   0.130493  \n",
      "\n",
      "CPU times: user 44.3 s, sys: 2.26 s, total: 46.5 s\n",
      "Wall time: 46.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.02157]), 0.13049284647330175]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time m.fit(lr, 1, metrics=[exp_rmspe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6bb9ffca0447e09f928107fd7880a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                        \n",
      "    0      0.010411   0.012753   0.11075   \n",
      "    1      0.009634   0.012503   0.105795                         \n",
      "    2      0.009381   0.013453   0.106811                         \n",
      "\n",
      "CPU times: user 2min 13s, sys: 5.25 s, total: 2min 19s\n",
      "Wall time: 2min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.01345]), 0.10681116485543725]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time m.fit(lr, 3, metrics=[exp_rmspe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4efbc984b348838a8f30c43f1b2652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                        \n",
      "    0      0.006373   0.010971   0.09824   \n",
      "    1      0.006826   0.010797   0.097719                         \n",
      "    2      0.006474   0.010548   0.09763                          \n",
      "    3      0.006935   0.010639   0.097766                         \n",
      "    4      0.006564   0.010407   0.096071                         \n",
      "\n",
      "CPU times: user 3min 39s, sys: 9.54 s, total: 3min 49s\n",
      "Wall time: 3min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.01041]), 0.09607056865511707]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time m.fit(lr, 5, metrics=[exp_rmspe], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177b2c89f92349fca6aa1df7d7f5d39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                        \n",
      "    0      0.006354   0.010429   0.095841  \n",
      "    1      0.005756   0.010345   0.096118                         \n",
      "    2      0.005986   0.010347   0.096728                         \n",
      "    3      0.005627   0.010452   0.096509                         \n",
      "\n",
      "CPU times: user 2min 56s, sys: 6.9 s, total: 3min 3s\n",
      "Wall time: 2min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.01045]), 0.09650949579673866]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time m.fit(lr, 4, metrics=[exp_rmspe], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('val0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09979241514057972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4475.422 ],\n",
       "       [ 7242.9165],\n",
       "       [ 9095.177 ],\n",
       "       [ 7343.125 ],\n",
       "       [ 7703.5986],\n",
       "       [ 5933.637 ],\n",
       "       [ 7425.5747],\n",
       "       [ 8448.557 ],\n",
       "       [ 5214.907 ],\n",
       "       [ 6099.194 ],\n",
       "       [ 7525.87  ],\n",
       "       [ 8438.476 ],\n",
       "       [ 7422.6226],\n",
       "       [ 9582.    ],\n",
       "       [ 6642.431 ],\n",
       "       [ 4793.3516],\n",
       "       [ 5958.497 ],\n",
       "       [ 9812.533 ],\n",
       "       [10718.219 ],\n",
       "       [ 9720.873 ],\n",
       "       ...,\n",
       "       [ 7418.5815],\n",
       "       [14485.122 ],\n",
       "       [ 6268.0366],\n",
       "       [ 5414.956 ],\n",
       "       [ 8090.2046],\n",
       "       [ 8611.748 ],\n",
       "       [ 3226.5671],\n",
       "       [ 8582.806 ],\n",
       "       [ 6945.2866],\n",
       "       [ 5872.405 ],\n",
       "       [ 6023.3833],\n",
       "       [ 5206.38  ],\n",
       "       [ 3075.9094],\n",
       "       [ 5696.65  ],\n",
       "       [ 3826.3704],\n",
       "       [ 2893.515 ],\n",
       "       [ 7348.253 ],\n",
       "       [ 6193.464 ],\n",
       "       [24672.73  ],\n",
       "       [ 7378.2866]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md = ColumnarModelData.from_data_frame(PATH, val_idx, df, yl.astype(np.float32), cat_flds=cat_vars, bs=128,\n",
    "                                       test_df=df_test)\n",
    "m = md.get_learner(emb_szs, len(df.columns)-len(cat_vars),\n",
    "                   0.04, 1, [1000,500], [0.001,0.01], y_range=y_range)\n",
    "m.load('val0')\n",
    "\n",
    "x,y=m.predict_with_targs()\n",
    "print(exp_rmspe(x,y))\n",
    "\n",
    "pred_test=m.predict(True)\n",
    "\n",
    "pred_test = np.exp(pred_test)\n",
    "\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_data_frame(PATH, val_idx, df, yl.astype(np.float32), cat_flds=cat_vars, bs=128,\n",
    "                                       test_df=df_test)\n",
    "m = md.get_learner(emb_szs, len(df.columns)-len(cat_vars),\n",
    "                   0.04, 1, [1000,500], [0.001,0.01], y_range=y_range)\n",
    "m.load('val0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4475.422 ],\n",
       "       [ 7242.9165],\n",
       "       [ 9095.177 ],\n",
       "       [ 7343.125 ],\n",
       "       [ 7703.5986],\n",
       "       [ 5933.637 ],\n",
       "       [ 7425.5747],\n",
       "       [ 8448.557 ],\n",
       "       [ 5214.907 ],\n",
       "       [ 6099.194 ],\n",
       "       [ 7525.87  ],\n",
       "       [ 8438.476 ],\n",
       "       [ 7422.6226],\n",
       "       [ 9582.    ],\n",
       "       [ 6642.431 ],\n",
       "       [ 4793.3516],\n",
       "       [ 5958.497 ],\n",
       "       [ 9812.533 ],\n",
       "       [10718.219 ],\n",
       "       [ 9720.873 ],\n",
       "       ...,\n",
       "       [ 7418.5815],\n",
       "       [14485.122 ],\n",
       "       [ 6268.0366],\n",
       "       [ 5414.956 ],\n",
       "       [ 8090.2046],\n",
       "       [ 8611.748 ],\n",
       "       [ 3226.5671],\n",
       "       [ 8582.806 ],\n",
       "       [ 6945.2866],\n",
       "       [ 5872.405 ],\n",
       "       [ 6023.3833],\n",
       "       [ 5206.38  ],\n",
       "       [ 3075.9094],\n",
       "       [ 5696.65  ],\n",
       "       [ 3826.3704],\n",
       "       [ 2893.515 ],\n",
       "       [ 7348.253 ],\n",
       "       [ 6193.464 ],\n",
       "       [24672.73  ],\n",
       "       [ 7378.2866]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columnar dataset\n",
    "cds = ColumnarDataset.from_data_frame(df_test,cat_vars)\n",
    "# data loader\n",
    "dl = DataLoader(cds,batch_size=128)\n",
    "# log predictions\n",
    "predictions = m.predict_dl(dl)\n",
    "# exp (log predictions) = predictions\n",
    "predictions=np.exp(predictions)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((val,trn), (y_val,y_trn)) = split_by_idx(val_idx, df.values, yl)\n",
    "mrf = RandomForestRegressor(n_estimators=40, max_features=0.99, min_samples_leaf=2,\n",
    "                          n_jobs=-1, oob_score=True)\n",
    "mrf.fit(trn, y_trn);\n",
    "\n",
    "preds = mrf.predict(val)\n",
    "mrf.score(trn, y_trn), mrf.score(val, y_val), mrf.oob_score_, exp_rmspe(preds, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9822761366872178,\n",
       " 0.9315735953865742,\n",
       " 0.9247582574628267,\n",
       " 0.10865527725952048)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrf.score(trn, y_trn), mrf.score(val, y_val), mrf.oob_score_, exp_rmspe(preds, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
